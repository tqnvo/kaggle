{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/categorical-variables).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"By encoding **categorical variables**, you'll obtain your best results thus far!\n\n# Setup\n\nThe questions below will give you feedback on your work. Run the following cell to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"# Set up code checking\nimport os\nif not os.path.exists(\"../input/train.csv\"):\n    os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n    os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\") \nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ml_intermediate.ex3 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:06:42.304949Z","iopub.execute_input":"2022-02-24T19:06:42.305476Z","iopub.status.idle":"2022-02-24T19:06:42.328008Z","shell.execute_reply.started":"2022-02-24T19:06:42.305379Z","shell.execute_reply":"2022-02-24T19:06:42.326996Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In this exercise, you will work with data from the [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course). \n\n![Ames Housing dataset image](https://i.imgur.com/lTJVG4e.png)\n\nRun the next code cell without changes to load the training and validation sets in `X_train`, `X_valid`, `y_train`, and `y_valid`.  The test set is loaded in `X_test`.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX = pd.read_csv('../input/train.csv', index_col='Id') \nX_test = pd.read_csv('../input/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X.SalePrice\nX.drop(['SalePrice'], axis=1, inplace=True)\n\n# To keep things simple, we'll drop columns with missing values\ncols_with_missing = [col for col in X.columns if X[col].isnull().any()] \nX.drop(cols_with_missing, axis=1, inplace=True)\nX_test.drop(cols_with_missing, axis=1, inplace=True)\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y,\n                                                      train_size=0.8, \n                                                      test_size=0.2,\n                                                      random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:06:42.329635Z","iopub.execute_input":"2022-02-24T19:06:42.329894Z","iopub.status.idle":"2022-02-24T19:06:43.017705Z","shell.execute_reply.started":"2022-02-24T19:06:42.329863Z","shell.execute_reply":"2022-02-24T19:06:43.016846Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Use the next code cell to print the first five rows of the data.","metadata":{}},{"cell_type":"code","source":"#print(X_train.head())\nprint(X_train.columns)\n#print(X_train.describe())\n#print(len(X_train.columns))\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:07:04.508042Z","iopub.execute_input":"2022-02-24T19:07:04.508882Z","iopub.status.idle":"2022-02-24T19:07:04.516336Z","shell.execute_reply.started":"2022-02-24T19:07:04.508814Z","shell.execute_reply":"2022-02-24T19:07:04.515388Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Index(['MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n       'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual',\n       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',\n       'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n       'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n       'Functional', 'Fireplaces', 'GarageCars', 'GarageArea', 'PavedDrive',\n       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n       'SaleCondition'],\n      dtype='object')\n(1168, 60)\n","output_type":"stream"}]},{"cell_type":"code","source":"#print(X_valid.head())\nprint(X_valid.columns)\n#print(X_valid.describe())\n#print(len(X_valid.columns))\nprint(X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:07:25.738085Z","iopub.execute_input":"2022-02-24T19:07:25.738805Z","iopub.status.idle":"2022-02-24T19:07:25.745171Z","shell.execute_reply.started":"2022-02-24T19:07:25.738752Z","shell.execute_reply":"2022-02-24T19:07:25.744476Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Index(['MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n       'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual',\n       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',\n       'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n       'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n       'Functional', 'Fireplaces', 'GarageCars', 'GarageArea', 'PavedDrive',\n       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n       'SaleCondition'],\n      dtype='object')\n(292, 60)\n","output_type":"stream"}]},{"cell_type":"code","source":"#print(X_test.head())\nprint(X_test.columns)\n#print(X_test.describe())\n#print(len(X_test.columns))\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:07:27.482905Z","iopub.execute_input":"2022-02-24T19:07:27.483447Z","iopub.status.idle":"2022-02-24T19:07:27.489321Z","shell.execute_reply.started":"2022-02-24T19:07:27.483408Z","shell.execute_reply":"2022-02-24T19:07:27.488579Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Index(['MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n       'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual',\n       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',\n       'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n       'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n       'Functional', 'Fireplaces', 'GarageCars', 'GarageArea', 'PavedDrive',\n       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n       'SaleCondition'],\n      dtype='object')\n(1459, 60)\n","output_type":"stream"}]},{"cell_type":"code","source":"#print(y_train)\n#print(y_train.head())\n#print(y_train.describe())","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:07:27.670296Z","iopub.execute_input":"2022-02-24T19:07:27.670697Z","iopub.status.idle":"2022-02-24T19:07:27.675749Z","shell.execute_reply.started":"2022-02-24T19:07:27.670661Z","shell.execute_reply":"2022-02-24T19:07:27.674744Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#print(y_valid)\n#print(y_valid.head())\n#print(y_valid.describe())","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:07:27.865369Z","iopub.execute_input":"2022-02-24T19:07:27.865803Z","iopub.status.idle":"2022-02-24T19:07:27.871563Z","shell.execute_reply.started":"2022-02-24T19:07:27.865761Z","shell.execute_reply":"2022-02-24T19:07:27.870297Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Notice that the dataset contains both numerical and categorical variables.  You'll need to encode the categorical data before training a model.\n\nTo compare different models, you'll use the same `score_dataset()` function from the tutorial.  This function reports the [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) from a random forest model.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=200, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:08:39.115606Z","iopub.execute_input":"2022-02-24T19:08:39.116030Z","iopub.status.idle":"2022-02-24T19:08:39.183501Z","shell.execute_reply.started":"2022-02-24T19:08:39.115993Z","shell.execute_reply":"2022-02-24T19:08:39.182411Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Step 1: Drop columns with categorical data\n\nYou'll get started with the most straightforward approach.  Use the code cell below to preprocess the data in `X_train` and `X_valid` to remove columns with categorical data.  Set the preprocessed DataFrames to `drop_X_train` and `drop_X_valid`, respectively.  ","metadata":{}},{"cell_type":"code","source":"# Fill in the lines below: drop columns in training and validation data\ndrop_X_train = X_train.select_dtypes(exclude=['object'])\ndrop_X_valid = X_valid.select_dtypes(exclude=['object'])\n\n# X_train has 60 columns, including 33 numerical cols and 27 categorical cols\n# X_valid has 60 columns, including 33 numerical cols and 27 categorical cols\nprint(len(X_train.columns))\nprint(len(drop_X_train.columns))\nprint(len(drop_X_valid.columns))\n\n# Check your answers\nstep_1.check()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:08:42.024138Z","iopub.execute_input":"2022-02-24T19:08:42.024502Z","iopub.status.idle":"2022-02-24T19:08:42.045875Z","shell.execute_reply.started":"2022-02-24T19:08:42.024465Z","shell.execute_reply":"2022-02-24T19:08:42.045184Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"60\n33\n33\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_Drop\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"#print(X_train.dtypes)\n#print(drop_X_train.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:10:35.138841Z","iopub.execute_input":"2022-02-24T19:10:35.139853Z","iopub.status.idle":"2022-02-24T19:10:35.144182Z","shell.execute_reply.started":"2022-02-24T19:10:35.139789Z","shell.execute_reply":"2022-02-24T19:10:35.143303Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#print(\"\\nUnique values in 'Condition2' column in training data:\", X_train['SaleType'].unique())\n#print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['SaleType'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:10:35.635789Z","iopub.execute_input":"2022-02-24T19:10:35.636568Z","iopub.status.idle":"2022-02-24T19:10:35.640195Z","shell.execute_reply.started":"2022-02-24T19:10:35.636514Z","shell.execute_reply":"2022-02-24T19:10:35.639390Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#print(\"\\nUnique values in 'Condition2' column in training data:\", X_train['Heating'].unique())\n#print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Heating'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:10:36.080854Z","iopub.execute_input":"2022-02-24T19:10:36.081577Z","iopub.status.idle":"2022-02-24T19:10:36.085582Z","shell.execute_reply.started":"2022-02-24T19:10:36.081525Z","shell.execute_reply":"2022-02-24T19:10:36.084804Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#step_1.hint()\n#step_1.solution()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:10:36.460088Z","iopub.execute_input":"2022-02-24T19:10:36.461369Z","iopub.status.idle":"2022-02-24T19:10:36.465599Z","shell.execute_reply.started":"2022-02-24T19:10:36.461289Z","shell.execute_reply":"2022-02-24T19:10:36.464558Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Run the next code cell to get the MAE for this approach.","metadata":{}},{"cell_type":"code","source":"#print(\"MAE from Approach 1 (Drop categorical variables):\")\n#print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:10:37.889447Z","iopub.execute_input":"2022-02-24T19:10:37.890369Z","iopub.status.idle":"2022-02-24T19:10:37.894079Z","shell.execute_reply.started":"2022-02-24T19:10:37.890317Z","shell.execute_reply":"2022-02-24T19:10:37.893376Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Before jumping into ordinal encoding, we'll investigate the dataset.  Specifically, we'll look at the `'Condition2'` column.  The code cell below prints the unique entries in both the training and validation sets.","metadata":{}},{"cell_type":"code","source":"print(\"\\nUnique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\nprint(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:10:38.979171Z","iopub.execute_input":"2022-02-24T19:10:38.979568Z","iopub.status.idle":"2022-02-24T19:10:38.989567Z","shell.execute_reply.started":"2022-02-24T19:10:38.979525Z","shell.execute_reply":"2022-02-24T19:10:38.988481Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nUnique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n\nUnique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Step 2: Ordinal encoding\n\n### Part A\n\nIf you now write code to: \n- fit an ordinal encoder to the training data, and then \n- use it to transform both the training and validation data, \n\nyou'll get an error.  Can you see why this is the case?  (_You'll need  to use the above output to answer this question._)","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\n#step_2.a.check()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:13:38.658683Z","iopub.execute_input":"2022-02-24T19:13:38.659450Z","iopub.status.idle":"2022-02-24T19:13:38.665129Z","shell.execute_reply.started":"2022-02-24T19:13:38.659382Z","shell.execute_reply":"2022-02-24T19:13:38.663730Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#step_2.a.hint()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:13:38.876946Z","iopub.execute_input":"2022-02-24T19:13:38.877354Z","iopub.status.idle":"2022-02-24T19:13:38.882501Z","shell.execute_reply.started":"2022-02-24T19:13:38.877299Z","shell.execute_reply":"2022-02-24T19:13:38.881466Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue.  For instance, you can write a custom ordinal encoder to deal with new categories.  The simplest approach, however, is to drop the problematic categorical columns.  \n\nRun the code cell below to save the problematic columns to a Python list `bad_label_cols`.  Likewise, columns that can be safely ordinal encoded are stored in `good_label_cols`.","metadata":{}},{"cell_type":"code","source":"# Categorical columns in the training data\nobject_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\nprint('[Train-Valid]\\n' + str(object_cols))\nprint('----> There are ' + str(len(object_cols)) + ' (good/bad) categorical columns in both Train and Valid sets.')\n\n# Columns that can be safely ordinal encoded\n# Checking 27 categorical columns to see if X_valid is a subset of X_train\n# If correct --> good set\n# If not --> bad set, to be dropped!\ngood_label_cols = [col for col in object_cols if set(X_valid[col]).issubset(set(X_train[col]))]\n        \n# Problematic columns that will be dropped from the dataset\nbad_label_cols = list(set(object_cols)-set(good_label_cols))\n\nprint('\\n[Train-Valid] Categorical columns that will be ordinal encoded:\\n', good_label_cols)\nprint('----> There are ' + str(len(good_label_cols)) + ' good categorical columns.')\nprint('\\n[Train-Valid] Categorical columns that will be dropped from the dataset:\\n', bad_label_cols)\nprint('----> There are ' + str(len(bad_label_cols)) + ' bad categorical columns.')","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:13:39.258751Z","iopub.execute_input":"2022-02-24T19:13:39.261397Z","iopub.status.idle":"2022-02-24T19:13:39.298986Z","shell.execute_reply.started":"2022-02-24T19:13:39.261282Z","shell.execute_reply":"2022-02-24T19:13:39.297557Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[Train-Valid]\n['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n----> There are 27 (good/bad) categorical columns in both Train and Valid sets.\n\n[Train-Valid] Categorical columns that will be ordinal encoded:\n ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']\n----> There are 24 good categorical columns.\n\n[Train-Valid] Categorical columns that will be dropped from the dataset:\n ['RoofMatl', 'Condition2', 'Functional']\n----> There are 3 bad categorical columns.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Part B\n\nUse the next code cell to ordinal encode the data in `X_train` and `X_valid`.  Set the preprocessed DataFrames to `label_X_train` and `label_X_valid`, respectively.  \n- We have provided code below to drop the categorical columns in `bad_label_cols` from the dataset. \n- You should ordinal encode the categorical columns in `good_label_cols`.  ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\n# Drop categorical columns that will not be encoded\nlabel_X_train = X_train.drop(bad_label_cols, axis=1)\nlabel_X_valid = X_valid.drop(bad_label_cols, axis=1)\n\nprint(label_X_train.columns)\nprint(len(label_X_train.columns))\n\n# Apply ordinal encoder \n# Your code here\nordinal_encoder = OrdinalEncoder()\nlabel_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\nlabel_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])\n    \n# Check your answer\nstep_2.b.check()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:13:40.731018Z","iopub.execute_input":"2022-02-24T19:13:40.731628Z","iopub.status.idle":"2022-02-24T19:13:40.794936Z","shell.execute_reply.started":"2022-02-24T19:13:40.731581Z","shell.execute_reply":"2022-02-24T19:13:40.793806Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Index(['MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n       'Condition1', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond',\n       'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'Exterior1st', 'Exterior2nd',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtFinSF1', 'BsmtFinSF2',\n       'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir',\n       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n       'KitchenQual', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea',\n       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n       'SaleCondition'],\n      dtype='object')\n57\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2.2_LabelB\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#step_2.b.hint()\n#step_2.b.solution()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:29:44.080258Z","iopub.execute_input":"2022-02-24T19:29:44.080700Z","iopub.status.idle":"2022-02-24T19:29:44.085237Z","shell.execute_reply.started":"2022-02-24T19:29:44.080658Z","shell.execute_reply":"2022-02-24T19:29:44.084509Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Run the next code cell to get the MAE for this approach.","metadata":{}},{"cell_type":"code","source":"print(\"MAE from Approach 2 (Ordinal Encoding):\") \nprint(score_dataset(label_X_train, label_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:29:45.048808Z","iopub.execute_input":"2022-02-24T19:29:45.049814Z","iopub.status.idle":"2022-02-24T19:29:48.247222Z","shell.execute_reply.started":"2022-02-24T19:29:45.049757Z","shell.execute_reply":"2022-02-24T19:29:48.245872Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"MAE from Approach 2 (Ordinal Encoding):\n16814.482208904108\n","output_type":"stream"}]},{"cell_type":"markdown","source":"So far, you've tried two different approaches to dealing with categorical variables.  And, you've seen that encoding categorical data yields better results than removing columns from the dataset.\n\nSoon, you'll try one-hot encoding.  Before then, there's one additional topic we need to cover.  Begin by running the next code cell without changes.  ","metadata":{}},{"cell_type":"code","source":"# Get number of unique entries in each column with categorical data\nobject_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\nd = dict(zip(object_cols, object_nunique))\n\n# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:29:50.253720Z","iopub.execute_input":"2022-02-24T19:29:50.254072Z","iopub.status.idle":"2022-02-24T19:29:50.271789Z","shell.execute_reply.started":"2022-02-24T19:29:50.254037Z","shell.execute_reply":"2022-02-24T19:29:50.270828Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[('Street', 2),\n ('Utilities', 2),\n ('CentralAir', 2),\n ('LandSlope', 3),\n ('PavedDrive', 3),\n ('LotShape', 4),\n ('LandContour', 4),\n ('ExterQual', 4),\n ('KitchenQual', 4),\n ('MSZoning', 5),\n ('LotConfig', 5),\n ('BldgType', 5),\n ('ExterCond', 5),\n ('HeatingQC', 5),\n ('Condition2', 6),\n ('RoofStyle', 6),\n ('Foundation', 6),\n ('Heating', 6),\n ('Functional', 6),\n ('SaleCondition', 6),\n ('RoofMatl', 7),\n ('HouseStyle', 8),\n ('Condition1', 9),\n ('SaleType', 9),\n ('Exterior1st', 15),\n ('Exterior2nd', 16),\n ('Neighborhood', 25)]"},"metadata":{}}]},{"cell_type":"code","source":"object_cols_test = [col for col in X_test.columns if X_test[col].dtype == \"object\"]\n# Get number of unique entries in each column with categorical data\nobject_nunique_test = list(map(lambda col: X_test[col].nunique(), object_cols_test))\nd = dict(zip(object_cols_test, object_nunique_test))\n\n# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:29:55.428043Z","iopub.execute_input":"2022-02-24T19:29:55.428426Z","iopub.status.idle":"2022-02-24T19:29:55.451800Z","shell.execute_reply.started":"2022-02-24T19:29:55.428381Z","shell.execute_reply":"2022-02-24T19:29:55.450695Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[('Utilities', 1),\n ('Street', 2),\n ('CentralAir', 2),\n ('LandSlope', 3),\n ('PavedDrive', 3),\n ('LotShape', 4),\n ('LandContour', 4),\n ('RoofMatl', 4),\n ('ExterQual', 4),\n ('Heating', 4),\n ('KitchenQual', 4),\n ('MSZoning', 5),\n ('LotConfig', 5),\n ('Condition2', 5),\n ('BldgType', 5),\n ('ExterCond', 5),\n ('HeatingQC', 5),\n ('RoofStyle', 6),\n ('Foundation', 6),\n ('SaleCondition', 6),\n ('HouseStyle', 7),\n ('Functional', 7),\n ('Condition1', 9),\n ('SaleType', 9),\n ('Exterior1st', 13),\n ('Exterior2nd', 15),\n ('Neighborhood', 25)]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Step 3: Investigating cardinality\n\n### Part A\n\nThe output above shows, for each column with categorical data, the number of unique values in the column.  For instance, the `'Street'` column in the training data has two unique values: `'Grvl'` and `'Pave'`, corresponding to a gravel road and a paved road, respectively.\n\nWe refer to the number of unique entries of a categorical variable as the **cardinality** of that categorical variable.  For instance, the `'Street'` variable has cardinality 2.\n\nUse the output above to answer the questions below.","metadata":{}},{"cell_type":"code","source":"# Fill in the line below: How many categorical variables in the training data\n# have cardinality greater than 10?\nhigh_cardinality_numcols = 3\n\n# Fill in the line below: How many columns are needed to one-hot encode the \n# 'Neighborhood' variable in the training data?\nnum_cols_neighborhood = 25\n\n# Check your answers\nstep_3.a.check()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:31:19.525247Z","iopub.execute_input":"2022-02-24T19:31:19.525667Z","iopub.status.idle":"2022-02-24T19:31:19.534270Z","shell.execute_reply.started":"2022-02-24T19:31:19.525616Z","shell.execute_reply":"2022-02-24T19:31:19.533567Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3.1_CardinalityA\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#step_3.a.hint()\n#step_3.a.solution()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:31:20.062490Z","iopub.execute_input":"2022-02-24T19:31:20.062885Z","iopub.status.idle":"2022-02-24T19:31:20.067350Z","shell.execute_reply.started":"2022-02-24T19:31:20.062840Z","shell.execute_reply":"2022-02-24T19:31:20.066401Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Part B\n\nFor large datasets with many rows, one-hot encoding can greatly expand the size of the dataset.  For this reason, we typically will only one-hot encode columns with relatively low cardinality.  Then, high cardinality columns can either be dropped from the dataset, or we can use ordinal encoding.\n\nAs an example, consider a dataset with 10,000 rows, and containing one categorical column with 100 unique entries.  \n- If this column is replaced with the corresponding one-hot encoding, how many entries are added to the dataset?  \n- If we instead replace the column with the ordinal encoding, how many entries are added?  \n\nUse your answers to fill in the lines below.","metadata":{}},{"cell_type":"code","source":"# Fill in the line below: How many entries are added to the dataset by \n# replacing the column with a one-hot encoding?\nOH_entries_added = 10000*100 - 10000\n\n# Fill in the line below: How many entries are added to the dataset by\n# replacing the column with an ordinal encoding?\nlabel_entries_added = 0\n\n# Check your answers\nstep_3.b.check()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:31:22.536782Z","iopub.execute_input":"2022-02-24T19:31:22.537761Z","iopub.status.idle":"2022-02-24T19:31:22.547118Z","shell.execute_reply.started":"2022-02-24T19:31:22.537703Z","shell.execute_reply":"2022-02-24T19:31:22.546397Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3.2_CardinalityB\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#step_3.b.hint()\n#step_3.b.solution()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:32:08.666775Z","iopub.execute_input":"2022-02-24T19:32:08.667177Z","iopub.status.idle":"2022-02-24T19:32:08.672302Z","shell.execute_reply.started":"2022-02-24T19:32:08.667132Z","shell.execute_reply":"2022-02-24T19:32:08.671143Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Next, you'll experiment with one-hot encoding.  But, instead of encoding all of the categorical variables in the dataset, you'll only create a one-hot encoding for columns with cardinality less than 10.\n\nRun the code cell below without changes to set `low_cardinality_cols` to a Python list containing the columns that will be one-hot encoded.  Likewise, `high_cardinality_cols` contains a list of categorical columns that will be dropped from the dataset.","metadata":{}},{"cell_type":"code","source":"# Columns that will be one-hot encoded\nlow_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n\n# Columns that will be dropped from the dataset\nhigh_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n\nprint('\\nCategorical columns that will be one-hot encoded:\\n', low_cardinality_cols)\nprint(len(low_cardinality_cols))\nprint('\\nCategorical columns that will be dropped from the dataset:\\n', high_cardinality_cols)\nprint(len(high_cardinality_cols))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:32:10.116093Z","iopub.execute_input":"2022-02-24T19:32:10.116484Z","iopub.status.idle":"2022-02-24T19:32:10.132789Z","shell.execute_reply.started":"2022-02-24T19:32:10.116448Z","shell.execute_reply":"2022-02-24T19:32:10.131279Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\nCategorical columns that will be one-hot encoded:\n ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n24\n\nCategorical columns that will be dropped from the dataset:\n ['Exterior2nd', 'Neighborhood', 'Exterior1st']\n3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Step 4: One-hot encoding\n\nUse the next code cell to one-hot encode the data in `X_train` and `X_valid`.  Set the preprocessed DataFrames to `OH_X_train` and `OH_X_valid`, respectively.  \n- The full list of categorical columns in the dataset can be found in the Python list `object_cols`.\n- You should only one-hot encode the categorical columns in `low_cardinality_cols`.  All other categorical columns should be dropped from the dataset. ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# Use as many lines of code as you need!\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\n#print('This is X_train[low_cardinality_cols]\\n')\n#print(X_train[low_cardinality_cols])\n#print('This is X_valid[low_cardinality_cols]\\n')\n#print(X_valid[low_cardinality_cols])\n\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n#print(OH_cols_train)\n#print(OH_cols_valid)\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_valid = X_valid.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n\n# Check your answer\nstep_4.check()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:38:33.913967Z","iopub.execute_input":"2022-02-24T19:38:33.914415Z","iopub.status.idle":"2022-02-24T19:38:33.968144Z","shell.execute_reply.started":"2022-02-24T19:38:33.914369Z","shell.execute_reply":"2022-02-24T19:38:33.967200Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"4_OneHot\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#step_4.hint()\n#step_4.solution()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:38:34.335082Z","iopub.execute_input":"2022-02-24T19:38:34.335428Z","iopub.status.idle":"2022-02-24T19:38:34.341647Z","shell.execute_reply.started":"2022-02-24T19:38:34.335389Z","shell.execute_reply":"2022-02-24T19:38:34.340414Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Run the next code cell to get the MAE for this approach.","metadata":{}},{"cell_type":"code","source":"print(\"MAE from Approach 3 (One-Hot Encoding):\") \nprint(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:38:35.593920Z","iopub.execute_input":"2022-02-24T19:38:35.594772Z","iopub.status.idle":"2022-02-24T19:38:39.572767Z","shell.execute_reply.started":"2022-02-24T19:38:35.594711Z","shell.execute_reply":"2022-02-24T19:38:39.571678Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"MAE from Approach 3 (One-Hot Encoding):\n17184.68566210046\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generate test predictions and submit your results\n\nAfter you complete Step 4, if you'd like to use what you've learned to submit your results to the leaderboard, you'll need to preprocess the test data before generating predictions.\n\n**This step is completely optional, and you do not need to submit results to the leaderboard to successfully complete the exercise.**\n\nCheck out the previous exercise if you need help with remembering how to [join the competition](https://www.kaggle.com/c/home-data-for-ml-course) or save your results to CSV.  Once you have generated a file with your results, follow the instructions below:\n1. Begin by clicking on the **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\nIf you want to keep working to improve your performance, select the **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n","metadata":{}},{"cell_type":"code","source":"# Good-bad\n\n# Categorical columns in the train/valid/test data\nobject_cols_train = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\nprint('X_train with shape ' + str(X_train.shape) + ' has ' + str(len(object_cols_train)) +'/' + str(len(X_train.columns)) + ' categorical columns.')\n\nobject_cols_valid = [col for col in X_valid.columns if X_valid[col].dtype == \"object\"]\nprint('X_valid with shape ' + str(X_valid.shape) + '  has ' + str(len(object_cols_valid)) +'/' + str(len(X_valid.columns)) + ' categorical columns.')\n\nobject_cols_test = [col for col in X_test.columns if X_test[col].dtype == \"object\"]\nprint('X_test  with shape ' + str(X_test.shape) + ' has ' + str(len(object_cols_test)) +'/' + str(len(X_test.columns)) + ' categorical columns.')\nprint('-----------------------------------------------------------------------------------')\n\n#--------------------------------------------------------------------------------------------------------------- [Train-Valid]\n# Columns that can be safely ordinal encoded: between X_train and X_valid\ngood_label_cols_trainvalid = [col for col in object_cols_train if \n                   set(X_valid[col]).issubset(set(X_train[col]))]\n        \n# Problematic columns that will be dropped from the dataset: between X_train and X_valid\nbad_label_cols_trainvalid = list(set(object_cols_train)-set(good_label_cols_trainvalid))\n\nprint('\\n[Train-Valid] Categorical columns that will be ordinal encoded:\\n', good_label_cols_trainvalid)\nprint('----> There are ' + str(len(good_label_cols_trainvalid)) + ' good categorical columns.')\nprint('\\n[Train-Valid] Categorical columns that will be dropped from the dataset:\\n', bad_label_cols_trainvalid)\nprint('----> There are ' + str(len(bad_label_cols_trainvalid)) + ' bad categorical columns.')\nprint('-----------------------------------------------------------------------------------')\nprint('-----------------------------------------------------------------------------------')\n\n#--------------------------------------------------------------------------------------------------------------- [Train-Test]\n# Columns that can be safely ordinal encoded: between X_train and X_test\ngood_label_cols_traintest = [col for col in object_cols_train if \n                   set(X_test[col]).issubset(set(X_train[col]))]\n        \n# Problematic columns that will be dropped from the dataset: between X_train and X_test\nbad_label_cols_traintest = list(set(object_cols_train)-set(good_label_cols_traintest))\n\nprint('\\n[Train-Test] Categorical columns that will be ordinal encoded:\\n', good_label_cols_traintest)\nprint('----> There are ' + str(len(good_label_cols_traintest)) + ' common-shared categorical columns between Train and Test.')\nprint('\\n[Train-Test] Categorical columns that will be dropped from the dataset:\\n', bad_label_cols_traintest)\nprint('----> These are sets in Train for sure, but maybe not in Test')\nprint('----> There are ' + str(len(bad_label_cols_traintest)) + ' non-common-shared categorical columns between Train and Test.')\nprint('-----------------------------------------------------------------------------------')\n\n#--------------------------------------------------------------------------------------------------------------- [Test-Train]\n# Columns that can be safely ordinal encoded: between X_train and X_test\ngood_label_cols_testtrain = [col for col in object_cols_test if \n                   set(X_train[col]).issubset(set(X_test[col]))]\n        \n# Problematic columns that will be dropped from the dataset: between X_train and X_test\nbad_label_cols_testtrain = list(set(object_cols_test)-set(good_label_cols_testtrain))\n        \nprint('\\n[Test-Train] Categorical columns that will be ordinal encoded:\\n', good_label_cols_testtrain)\nprint('----> There are ' + str(len(good_label_cols_testtrain)) + ' common-shared categorical columns between Train and Test.')\nprint('\\n[Test-Train] Categorical columns that will be dropped from the dataset:\\n', bad_label_cols_testtrain)\nprint('----> These are sets in Test for sure, but maybe not in Train')\nprint('----> There are ' + str(len(bad_label_cols_testtrain)) + ' non-common-shared categorical columns between Train and Test.')\nprint('-----------------------------------------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:41:33.332124Z","iopub.execute_input":"2022-02-24T19:41:33.332786Z","iopub.status.idle":"2022-02-24T19:41:33.385546Z","shell.execute_reply.started":"2022-02-24T19:41:33.332737Z","shell.execute_reply":"2022-02-24T19:41:33.384423Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"X_train with shape (1168, 60) has 27/60 categorical columns.\nX_valid with shape (292, 60)  has 27/60 categorical columns.\nX_test  with shape (1459, 60) has 27/60 categorical columns.\n-----------------------------------------------------------------------------------\n\n[Train-Valid] Categorical columns that will be ordinal encoded:\n ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']\n----> There are 24 good categorical columns.\n\n[Train-Valid] Categorical columns that will be dropped from the dataset:\n ['RoofMatl', 'Condition2', 'Functional']\n----> There are 3 bad categorical columns.\n-----------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------\n\n[Train-Test] Categorical columns that will be ordinal encoded:\n ['Street', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'PavedDrive', 'SaleCondition']\n----> There are 20 common-shared categorical columns between Train and Test.\n\n[Train-Test] Categorical columns that will be dropped from the dataset:\n ['Exterior2nd', 'SaleType', 'Exterior1st', 'Utilities', 'KitchenQual', 'MSZoning', 'Functional']\n----> These are sets in Train for sure, but maybe not in Test\n----> There are 7 non-common-shared categorical columns between Train and Test.\n-----------------------------------------------------------------------------------\n\n[Test-Train] Categorical columns that will be ordinal encoded:\n ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'RoofStyle', 'ExterQual', 'ExterCond', 'Foundation', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n----> There are 20 common-shared categorical columns between Train and Test.\n\n[Test-Train] Categorical columns that will be dropped from the dataset:\n ['Exterior2nd', 'RoofMatl', 'Condition2', 'Exterior1st', 'HouseStyle', 'Utilities', 'Heating']\n----> These are sets in Test for sure, but maybe not in Train\n----> There are 7 non-common-shared categorical columns between Train and Test.\n-----------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"# Drop those columns in X_test and X_train whose entries do not belong to both sets\n# This can be checked by frequency\n# They may have the same column name but variations are different from each other\n\n# Drop categorical columns that will not be one-hot encoded from columns of test set X_test\nfinal_label_X_train = X_train.drop(bad_label_cols_traintest, axis=1)\nfinal_label_X_test = X_test.drop(bad_label_cols_traintest, axis=1)\n\n#print(final_label_X_train.columns)\n#print(final_label_X_test.columns)\nprint(len(final_label_X_train.columns))\nprint(len(final_label_X_test.columns))\n\n# Apply ordinal encoder \n# Your code here\n#ordinal_encoder = OrdinalEncoder()\n#label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n#label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:41:36.592735Z","iopub.execute_input":"2022-02-24T19:41:36.593657Z","iopub.status.idle":"2022-02-24T19:41:36.607998Z","shell.execute_reply.started":"2022-02-24T19:41:36.593599Z","shell.execute_reply":"2022-02-24T19:41:36.606838Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"53\n53\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cardinality\n# Check frequencies again: final_label_X_test\n\nobject_cols_test_again = [col for col in final_label_X_test.columns if final_label_X_test[col].dtype == \"object\"]\n# Get number of unique entries in each column with categorical data\nobject_nunique_test_again = list(map(lambda col: final_label_X_test[col].nunique(), object_cols_test_again))\nd = dict(zip(object_cols_test_again, object_nunique_test_again))\n\n# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])\n# Sorting by ascending order of alphabet\n#sorted(d.items(), key=lambda x: x[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:50:33.265227Z","iopub.execute_input":"2022-02-24T19:50:33.266243Z","iopub.status.idle":"2022-02-24T19:50:33.285349Z","shell.execute_reply.started":"2022-02-24T19:50:33.266158Z","shell.execute_reply":"2022-02-24T19:50:33.284163Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"[('Street', 2),\n ('CentralAir', 2),\n ('LandSlope', 3),\n ('PavedDrive', 3),\n ('LotShape', 4),\n ('LandContour', 4),\n ('RoofMatl', 4),\n ('ExterQual', 4),\n ('Heating', 4),\n ('LotConfig', 5),\n ('Condition2', 5),\n ('BldgType', 5),\n ('ExterCond', 5),\n ('HeatingQC', 5),\n ('RoofStyle', 6),\n ('Foundation', 6),\n ('SaleCondition', 6),\n ('HouseStyle', 7),\n ('Condition1', 9),\n ('Neighborhood', 25)]"},"metadata":{}}]},{"cell_type":"code","source":"# Cardinality\n# Check frequencies again: final_label_X_train\n\nobject_cols_train_again = [col for col in final_label_X_train.columns if final_label_X_train[col].dtype == \"object\"]\n# Get number of unique entries in each column with categorical data\nobject_nunique_train_again = list(map(lambda col: final_label_X_train[col].nunique(), object_cols_train_again))\nd = dict(zip(object_cols_train_again, object_nunique_train_again))\n\n# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])\n# Sorting by ascending order of alphabet\n#sorted(d.items(), key=lambda x: x[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:50:34.141799Z","iopub.execute_input":"2022-02-24T19:50:34.142812Z","iopub.status.idle":"2022-02-24T19:50:34.163644Z","shell.execute_reply.started":"2022-02-24T19:50:34.142738Z","shell.execute_reply":"2022-02-24T19:50:34.162478Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"[('Street', 2),\n ('CentralAir', 2),\n ('LandSlope', 3),\n ('PavedDrive', 3),\n ('LotShape', 4),\n ('LandContour', 4),\n ('ExterQual', 4),\n ('LotConfig', 5),\n ('BldgType', 5),\n ('ExterCond', 5),\n ('HeatingQC', 5),\n ('Condition2', 6),\n ('RoofStyle', 6),\n ('Foundation', 6),\n ('Heating', 6),\n ('SaleCondition', 6),\n ('RoofMatl', 7),\n ('HouseStyle', 8),\n ('Condition1', 9),\n ('Neighborhood', 25)]"},"metadata":{}}]},{"cell_type":"code","source":"# Note:\n# The preprocessed DataFrames have the same number of columns\n# The preprocessed DataFrames have no missing values","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:50:55.599953Z","iopub.execute_input":"2022-02-24T19:50:55.600317Z","iopub.status.idle":"2022-02-24T19:50:55.604956Z","shell.execute_reply.started":"2022-02-24T19:50:55.600268Z","shell.execute_reply":"2022-02-24T19:50:55.604135Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n#OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n##print(OH_cols_train)\n##print(OH_cols_valid)\n\n## One-hot encoding removed index; put it back\n#OH_cols_train.index = X_train.index\n#OH_cols_valid.index = X_valid.index\n\n## Remove categorical columns (will replace with one-hot encoding)\n#num_X_train = X_train.drop(object_cols, axis=1)\n#num_X_valid = X_valid.drop(object_cols, axis=1)\n\n## Add one-hot encoded columns to numerical features\n#OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n#OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:52:38.838260Z","iopub.execute_input":"2022-02-24T19:52:38.839061Z","iopub.status.idle":"2022-02-24T19:52:38.844327Z","shell.execute_reply.started":"2022-02-24T19:52:38.839004Z","shell.execute_reply":"2022-02-24T19:52:38.843222Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Define and fit model\n#model = RandomForestRegressor(n_estimators=200, random_state=0)\n#model.fit(OH_X_train,y_train)\n\n#print(X_test[test_low_cardinality_cols])\n#print(X_test[test_low_cardinality_cols].columns)\n\n# Apply one-hot encoder to each column with categorical data\nOH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_test.index = X_test.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_test = X_test.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:54:56.091455Z","iopub.execute_input":"2022-02-24T19:54:56.092657Z","iopub.status.idle":"2022-02-24T19:54:56.229321Z","shell.execute_reply.started":"2022-02-24T19:54:56.092586Z","shell.execute_reply":"2022-02-24T19:54:56.227797Z"},"trusted":true},"execution_count":48,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_148/2654260705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Apply one-hot encoder to each column with categorical data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mOH_cols_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOH_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlow_cardinality_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# One-hot encoding removed index; put it back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# validation of X happens in _check_X called by _transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mX_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_int\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mX_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mX_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mXi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             Xi = check_array(Xi, ensure_2d=False, dtype=None,\n\u001b[0;32m---> 61\u001b[0;31m                              force_all_finite=needs_validation)\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mX_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 645\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input contains NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN"],"ename":"ValueError","evalue":"Input contains NaN","output_type":"error"}]},{"cell_type":"code","source":"# Define and fit model\nmodel = RandomForestRegressor(n_estimators=10000, random_state=0)\nmodel.fit(final_X_train, y_train)\n\n# Get validation predictions and MAE\npreds_valid = model.predict(final_X_valid)\nprint(\"MAE (Your approach):\")\nprint(mean_absolute_error(y_valid, preds_valid))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill in the line below: preprocess test data\nfinal_X_test = pd.DataFrame(final_imputer.transform(X_test))\n\n# Fill in the line below: get test predictions\npreds_test = model.predict(final_X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keep going\n\nWith missing value handling and categorical encoding, your modeling process is getting complex. This complexity gets worse when you want to save your model to use in the future. The key to managing this complexity is something called **pipelines**. \n\n**[Learn to use pipelines](https://www.kaggle.com/alexisbcook/pipelines)** to preprocess datasets with categorical variables, missing values and any other messiness your data throws at you.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intermediate-machine-learning/discussion) to chat with other learners.*","metadata":{}}]}